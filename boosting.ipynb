{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from evaluate import get_score\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "from lightgbm import LGBMClassifier as LGBM\n",
    "from lightgbm import LGBMRegressor as LGBMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/clean_train.csv')\n",
    "train_x = train.drop(columns = ['AdoptionSpeed'])\n",
    "train_y = train['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_GRID = {\n",
    "    'max_depth': [6, 7],\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [200],\n",
    "    'reg_alpha': [0],\n",
    "    'reg_lambda': [0, 0.001, 0.003, 0.1],\n",
    "}\n",
    "xgb = XGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_GRID = {\n",
    "    'num_leaves': [20, 50, 100],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'n_estimators': [200],\n",
    "    'subsample_for_bin': [2000],\n",
    "    'min_child_samples': [25],\n",
    "    'reg_alpha': [0],\n",
    "    'reg_lambda': [0, 0.1],\n",
    "}\n",
    "lgbm = LGBM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(get_score, greater_is_better = True)\n",
    "ss = ShuffleSplit(n_splits = 5, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e4fb779443fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGB_GRID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = xgb, param_grid = XGB_GRID, scoring = scorer, cv = ss, n_jobs = -1)\n",
    "grid_search.fit(train_x.values, train_y.values)\n",
    "cv_df = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_df.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/huang/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_samples</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.036347</td>\n",
       "      <td>0.230582</td>\n",
       "      <td>0.979198</td>\n",
       "      <td>0.594688</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353210</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500950</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.500870</td>\n",
       "      <td>0.519549</td>\n",
       "      <td>0.499364</td>\n",
       "      <td>0.503086</td>\n",
       "      <td>0.008541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.942066</td>\n",
       "      <td>0.191549</td>\n",
       "      <td>1.082606</td>\n",
       "      <td>0.392277</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353210</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500950</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.500870</td>\n",
       "      <td>0.519549</td>\n",
       "      <td>0.499364</td>\n",
       "      <td>0.503086</td>\n",
       "      <td>0.008541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.010782</td>\n",
       "      <td>0.334271</td>\n",
       "      <td>1.622404</td>\n",
       "      <td>0.637375</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353190</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>3</td>\n",
       "      <td>0.566323</td>\n",
       "      <td>0.578491</td>\n",
       "      <td>0.562960</td>\n",
       "      <td>0.590471</td>\n",
       "      <td>0.568877</td>\n",
       "      <td>0.573424</td>\n",
       "      <td>0.009969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.374925</td>\n",
       "      <td>0.174943</td>\n",
       "      <td>2.458990</td>\n",
       "      <td>0.534697</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352292</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>4</td>\n",
       "      <td>0.636482</td>\n",
       "      <td>0.647035</td>\n",
       "      <td>0.627423</td>\n",
       "      <td>0.652680</td>\n",
       "      <td>0.637873</td>\n",
       "      <td>0.640299</td>\n",
       "      <td>0.008774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.050200</td>\n",
       "      <td>0.105529</td>\n",
       "      <td>1.302007</td>\n",
       "      <td>0.482863</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351556</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>5</td>\n",
       "      <td>0.571759</td>\n",
       "      <td>0.574765</td>\n",
       "      <td>0.563510</td>\n",
       "      <td>0.587208</td>\n",
       "      <td>0.569464</td>\n",
       "      <td>0.573341</td>\n",
       "      <td>0.007855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.973975</td>\n",
       "      <td>0.101108</td>\n",
       "      <td>1.280237</td>\n",
       "      <td>0.493773</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351256</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>6</td>\n",
       "      <td>0.504334</td>\n",
       "      <td>0.503393</td>\n",
       "      <td>0.510805</td>\n",
       "      <td>0.526944</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.511355</td>\n",
       "      <td>0.008438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.817647</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>2.027609</td>\n",
       "      <td>0.271244</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350855</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>7</td>\n",
       "      <td>0.489120</td>\n",
       "      <td>0.488387</td>\n",
       "      <td>0.488836</td>\n",
       "      <td>0.503407</td>\n",
       "      <td>0.490153</td>\n",
       "      <td>0.491981</td>\n",
       "      <td>0.005743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.798891</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>1.178486</td>\n",
       "      <td>0.667634</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>8</td>\n",
       "      <td>0.489803</td>\n",
       "      <td>0.482592</td>\n",
       "      <td>0.485158</td>\n",
       "      <td>0.503997</td>\n",
       "      <td>0.484426</td>\n",
       "      <td>0.489195</td>\n",
       "      <td>0.007773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.809491</td>\n",
       "      <td>0.356414</td>\n",
       "      <td>1.702875</td>\n",
       "      <td>0.514270</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349454</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>9</td>\n",
       "      <td>0.568579</td>\n",
       "      <td>0.570281</td>\n",
       "      <td>0.565985</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.570464</td>\n",
       "      <td>0.570698</td>\n",
       "      <td>0.004073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.583586</td>\n",
       "      <td>0.111942</td>\n",
       "      <td>0.922250</td>\n",
       "      <td>0.107190</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349219</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>10</td>\n",
       "      <td>0.520678</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>0.528270</td>\n",
       "      <td>0.538087</td>\n",
       "      <td>0.520787</td>\n",
       "      <td>0.525706</td>\n",
       "      <td>0.006846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.478075</td>\n",
       "      <td>0.282557</td>\n",
       "      <td>2.648557</td>\n",
       "      <td>1.449026</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349038</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>11</td>\n",
       "      <td>0.621233</td>\n",
       "      <td>0.634306</td>\n",
       "      <td>0.617968</td>\n",
       "      <td>0.640252</td>\n",
       "      <td>0.625558</td>\n",
       "      <td>0.627863</td>\n",
       "      <td>0.008273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.810125</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>1.345402</td>\n",
       "      <td>0.324266</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348668</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>12</td>\n",
       "      <td>0.503993</td>\n",
       "      <td>0.499288</td>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.519063</td>\n",
       "      <td>0.498605</td>\n",
       "      <td>0.504068</td>\n",
       "      <td>0.007739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.988429</td>\n",
       "      <td>0.104761</td>\n",
       "      <td>1.097170</td>\n",
       "      <td>0.179707</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348668</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>12</td>\n",
       "      <td>0.503993</td>\n",
       "      <td>0.499288</td>\n",
       "      <td>0.499391</td>\n",
       "      <td>0.519063</td>\n",
       "      <td>0.498605</td>\n",
       "      <td>0.504068</td>\n",
       "      <td>0.007739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.383259</td>\n",
       "      <td>0.216846</td>\n",
       "      <td>1.728994</td>\n",
       "      <td>0.900392</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348476</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>14</td>\n",
       "      <td>0.618771</td>\n",
       "      <td>0.633064</td>\n",
       "      <td>0.621269</td>\n",
       "      <td>0.642231</td>\n",
       "      <td>0.631181</td>\n",
       "      <td>0.629303</td>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.116430</td>\n",
       "      <td>0.351127</td>\n",
       "      <td>1.473149</td>\n",
       "      <td>0.436848</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347752</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>15</td>\n",
       "      <td>0.569947</td>\n",
       "      <td>0.578215</td>\n",
       "      <td>0.563476</td>\n",
       "      <td>0.586410</td>\n",
       "      <td>0.566428</td>\n",
       "      <td>0.572895</td>\n",
       "      <td>0.008369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.679408</td>\n",
       "      <td>0.100888</td>\n",
       "      <td>1.153819</td>\n",
       "      <td>0.452839</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346963</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>16</td>\n",
       "      <td>0.510318</td>\n",
       "      <td>0.513328</td>\n",
       "      <td>0.511424</td>\n",
       "      <td>0.521389</td>\n",
       "      <td>0.510644</td>\n",
       "      <td>0.513421</td>\n",
       "      <td>0.004119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.441716</td>\n",
       "      <td>0.137207</td>\n",
       "      <td>0.653240</td>\n",
       "      <td>0.108579</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345426</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>17</td>\n",
       "      <td>0.521396</td>\n",
       "      <td>0.523194</td>\n",
       "      <td>0.519985</td>\n",
       "      <td>0.541038</td>\n",
       "      <td>0.524444</td>\n",
       "      <td>0.526011</td>\n",
       "      <td>0.007666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.849583</td>\n",
       "      <td>1.159651</td>\n",
       "      <td>1.438284</td>\n",
       "      <td>0.988991</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342371</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>18</td>\n",
       "      <td>0.636756</td>\n",
       "      <td>0.638963</td>\n",
       "      <td>0.626529</td>\n",
       "      <td>0.651465</td>\n",
       "      <td>0.634424</td>\n",
       "      <td>0.637627</td>\n",
       "      <td>0.008093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3        4.036347      0.230582         0.979198        0.594688   \n",
       "5        3.942066      0.191549         1.082606        0.392277   \n",
       "8        4.010782      0.334271         1.622404        0.637375   \n",
       "16       4.374925      0.174943         2.458990        0.534697   \n",
       "11       4.050200      0.105529         1.302007        0.482863   \n",
       "6        3.973975      0.101108         1.280237        0.493773   \n",
       "0        3.817647      0.016347         2.027609        0.271244   \n",
       "1        3.798891      0.061882         1.178486        0.667634   \n",
       "9        3.809491      0.356414         1.702875        0.514270   \n",
       "13       3.583586      0.111942         0.922250        0.107190   \n",
       "15       4.478075      0.282557         2.648557        1.449026   \n",
       "2        3.810125      0.040589         1.345402        0.324266   \n",
       "4        3.988429      0.104761         1.097170        0.179707   \n",
       "14       4.383259      0.216846         1.728994        0.900392   \n",
       "10       4.116430      0.351127         1.473149        0.436848   \n",
       "7        3.679408      0.100888         1.153819        0.452839   \n",
       "12       3.441716      0.137207         0.653240        0.108579   \n",
       "17       4.849583      1.159651         1.438284        0.988991   \n",
       "\n",
       "   param_max_depth param_min_child_samples param_n_estimators  \\\n",
       "3                5                      25                200   \n",
       "5                5                      25                200   \n",
       "8                6                      25                200   \n",
       "16               7                      25                200   \n",
       "11               6                      25                200   \n",
       "6                6                      25                200   \n",
       "0                5                      25                200   \n",
       "1                5                      25                200   \n",
       "9                6                      25                200   \n",
       "13               7                      25                200   \n",
       "15               7                      25                200   \n",
       "2                5                      25                200   \n",
       "4                5                      25                200   \n",
       "14               7                      25                200   \n",
       "10               6                      25                200   \n",
       "7                6                      25                200   \n",
       "12               7                      25                200   \n",
       "17               7                      25                200   \n",
       "\n",
       "   param_num_leaves param_reg_alpha param_reg_lambda       ...         \\\n",
       "3                50               0              0.1       ...          \n",
       "5               100               0              0.1       ...          \n",
       "8                50               0                0       ...          \n",
       "16              100               0                0       ...          \n",
       "11              100               0              0.1       ...          \n",
       "6                20               0                0       ...          \n",
       "0                20               0                0       ...          \n",
       "1                20               0              0.1       ...          \n",
       "9                50               0              0.1       ...          \n",
       "13               20               0              0.1       ...          \n",
       "15               50               0              0.1       ...          \n",
       "2                50               0                0       ...          \n",
       "4               100               0                0       ...          \n",
       "14               50               0                0       ...          \n",
       "10              100               0                0       ...          \n",
       "7                20               0              0.1       ...          \n",
       "12               20               0                0       ...          \n",
       "17              100               0              0.1       ...          \n",
       "\n",
       "   mean_test_score std_test_score  rank_test_score  split0_train_score  \\\n",
       "3         0.353210       0.007920                1            0.500950   \n",
       "5         0.353210       0.007920                1            0.500950   \n",
       "8         0.353190       0.009273                3            0.566323   \n",
       "16        0.352292       0.009094                4            0.636482   \n",
       "11        0.351556       0.009959                5            0.571759   \n",
       "6         0.351256       0.005342                6            0.504334   \n",
       "0         0.350855       0.005719                7            0.489120   \n",
       "1         0.350716       0.004722                8            0.489803   \n",
       "9         0.349454       0.007942                9            0.568579   \n",
       "13        0.349219       0.006776               10            0.520678   \n",
       "15        0.349038       0.005609               11            0.621233   \n",
       "2         0.348668       0.004999               12            0.503993   \n",
       "4         0.348668       0.004999               12            0.503993   \n",
       "14        0.348476       0.004910               14            0.618771   \n",
       "10        0.347752       0.002980               15            0.569947   \n",
       "7         0.346963       0.005495               16            0.510318   \n",
       "12        0.345426       0.009071               17            0.521396   \n",
       "17        0.342371       0.003863               18            0.636756   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "3             0.494700            0.500870            0.519549   \n",
       "5             0.494700            0.500870            0.519549   \n",
       "8             0.578491            0.562960            0.590471   \n",
       "16            0.647035            0.627423            0.652680   \n",
       "11            0.574765            0.563510            0.587208   \n",
       "6             0.503393            0.510805            0.526944   \n",
       "0             0.488387            0.488836            0.503407   \n",
       "1             0.482592            0.485158            0.503997   \n",
       "9             0.570281            0.565985            0.578182   \n",
       "13            0.520710            0.528270            0.538087   \n",
       "15            0.634306            0.617968            0.640252   \n",
       "2             0.499288            0.499391            0.519063   \n",
       "4             0.499288            0.499391            0.519063   \n",
       "14            0.633064            0.621269            0.642231   \n",
       "10            0.578215            0.563476            0.586410   \n",
       "7             0.513328            0.511424            0.521389   \n",
       "12            0.523194            0.519985            0.541038   \n",
       "17            0.638963            0.626529            0.651465   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "3             0.499364          0.503086         0.008541  \n",
       "5             0.499364          0.503086         0.008541  \n",
       "8             0.568877          0.573424         0.009969  \n",
       "16            0.637873          0.640299         0.008774  \n",
       "11            0.569464          0.573341         0.007855  \n",
       "6             0.511300          0.511355         0.008438  \n",
       "0             0.490153          0.491981         0.005743  \n",
       "1             0.484426          0.489195         0.007773  \n",
       "9             0.570464          0.570698         0.004073  \n",
       "13            0.520787          0.525706         0.006846  \n",
       "15            0.625558          0.627863         0.008273  \n",
       "2             0.498605          0.504068         0.007739  \n",
       "4             0.498605          0.504068         0.007739  \n",
       "14            0.631181          0.629303         0.008488  \n",
       "10            0.566428          0.572895         0.008369  \n",
       "7             0.510644          0.513421         0.004119  \n",
       "12            0.524444          0.526011         0.007666  \n",
       "17            0.634424          0.637627         0.008093  \n",
       "\n",
       "[18 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = lgbm, param_grid = LGBM_GRID, scoring = scorer, cv = ss, n_jobs = -1)\n",
    "grid_search.fit(train_x.values, train_y.values)\n",
    "cv_df = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_df.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test/test.csv')\n",
    "test_x = test.drop(columns = ['Name', 'RescuerID', 'PetID', 'Description'])\n",
    "pet_id = test['PetID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_PARAMS = {\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 200,\n",
    "    'subsample_for_bin': 2000,\n",
    "    'min_child_samples': 25,\n",
    "    'reg_lambda': 0.01\n",
    "}\n",
    "lgbm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lgbm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'PetID': pet_id, 'AdoptionSpeed': predict})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
